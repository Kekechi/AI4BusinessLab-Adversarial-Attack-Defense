[009.json](data/json/009.json)
 
## 1. Main Question

- What problem is the paper trying to solve? (1–2 sentences)
Adversarial attack in physical world
## 2. Key Method

- One-line description of the main attack/defense.
- Use glossary terms when possible (e.g., “FGSM = adds noise along gradient sign”).
Print Adversarial attack and test it against system with camera to input
Introduce Iterative method, apply FGSM multiple times. (AKA. BIM attack)
## 3. Main Results

- One key experiment (dataset + outcome).
- Quote numbers if easy (e.g., “Error reduced from 0.94% → 0.84% on MNIST”).
No modification required. Just printing image works against system that uses camera/
## 4. Strengths & Limitations

- 1 bullet strength (e.g., “Simple and reproducible”).
- 1 bullet limitation (e.g., “Only tested on images, white-box only”).

## 5. Applications / Relevance

- If any — real-world link, or why it matters for other research.

## 6. Self-Check

- **2-minute explanation**: Could you explain this to a classmate? Write 2–3 plain sentences.
- **Unknown terms**: List any jargon you didn’t fully get (e.g., “maxout network,” “universal approximator theorem”).
The paper tests validity of adversarial attack in the real world scenarios where camera exists between user and the classifier model. It found that just printing an adversarial example works very well.